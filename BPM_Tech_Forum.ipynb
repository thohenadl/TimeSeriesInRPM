{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation of User Interaction Logs using Time Series Methods\n",
    "\n",
    "A demo case used for the idea paper at CAISE 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import stumpy\n",
    "from stumpy import config\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import util.util\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pm4py\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Gathering\n",
    "\n",
    "Read the Logs that should be discovered from the folder \"Leno\".\n",
    "\n",
    "Adjust the file names according to your needs:\n",
    "1. SRRT_Plus => The file that contains the sequentially ordered traces\n",
    "2. SRRT_Parallel => The file that contains the alternating traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Leno/'\n",
    "# The following two files were used in the Experiment in the paper\n",
    "srrt_plus_filename = \"experiment_extended_SR_RT_joint.csv\"\n",
    "srrt_parallel_filename = \"experiment_extended_SR_RT_parallel.csv\"\n",
    "\n",
    "text_encoding_method = \"utf-8\"\n",
    "seperator = \";\"\n",
    "\n",
    "srrt_plus_log = pd.read_csv(file_path + srrt_plus_filename, encoding=text_encoding_method, sep=seperator)\n",
    "srrt_parallel_log = pd.read_csv(file_path + srrt_parallel_filename, encoding=text_encoding_method, sep=seperator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Word2Vec Encoding Single Window Size Discovery\n",
    "\n",
    "Single Sentence Word2Vec encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Im Paper Änderungen\n",
    "1. Methodenbeschreibung anpassen > Word2Vec\n",
    "2. A reduced set of parameters provides better results as described in Matrix Profil 4 paper, \n",
    "    a Method to identify the best set of parameters for mining the data has to be developed.\n",
    "2. Multi-Dimensionale Motif discovery\n",
    "3. Experiment mit dieser Encoding method durchführen und ergebnisskurve auswerten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  80  240  321  402  643  724  805  965 1046 1209]]\n",
      "Ground Truth:[   0   79  130  241  323  434  514  625  707  818  900 1011 1093 1204\n",
      " 1284 1396 1538 1591 1671 1782 1864 1975 2057 2168 2248 2359 2441 2552\n",
      " 2634 2745 2828 2939 3021 3135 3215 3326 3469 3522 3660 3715 3793 3904\n",
      " 3986 4097 4180 4291 4373 4484 4566 4677 4757 4868 4948 5059 5141 5252\n",
      " 5334 5445 5527 5638 5720 5833 5916 6027 6109 6220 6302 6413 6495 6606\n",
      " 6688 6799 6882 6993 7075 7186 7268 7379 7461 7572 7654 7765 7847 7958\n",
      " 8040 8152 8234 8345 8427 8538 8620 8731 8813 8925 9007 9118 9200 9311\n",
      " 9393 9504]\n",
      "Precision: 0.4\n",
      "Recall: 0.04\n",
      "F1-Score: 0.07272727272727272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# ---- Inputs ----\n",
    "log_to_discover = srrt_plus_log\n",
    "# OR\n",
    "log_to_discover = srrt_parallel_log\n",
    "\n",
    "window_size = 30\n",
    "motifs_to_discover = 10\n",
    "\n",
    "\n",
    "columns_to_use = ['eventType', 'targetApp', 'target.tagName', 'target.name']\n",
    "#columns_to_use = [\"targetApp\",\"eventType\",\"url\",\"target.workbookName\",\"target.sheetName\",\"target.id\",\"target.class\",\"target.tagName\",\"target.type\",\"target.name\",\"target.innerText\",\"target.checked\",\"target.href\",\"target.option\",\"target.title\",\"target.innerHTML\"]\n",
    "\n",
    "# ---- Single Log execution ----\n",
    "groundTruth = util.util.generate_caseid_list(log_to_discover) \n",
    "ui_log_encoded_w2v = util.util.encode_word2vec(srrt_plus_log, orderedColumnsList=columns_to_use)\n",
    "motif_distances, motif_indices, motif_subspaces, motif_mdls = util.util.mine_w2v(ui_log_encoded_w2v,window_size,motifs_to_discover)\n",
    "print(motif_indices)\n",
    "\n",
    "print(f\"Ground Truth:{np.sort(groundTruth)}\")\n",
    "\n",
    "# ---- Measuring Method: Half the Window Size ----\n",
    "# insert_spots, motif_spots, overlapDF = util.util.compare_sets(set(groundTruth), set(motif_indices[0]), (size/2))\n",
    "# ---- Measuring Method: Intersection over Union\n",
    "insert_spots, motif_spots, overlapDF = util.util.compare_sets_IoU(set(groundTruth), set(motif_indices[0]), window_size, iou_threshold=0.7)\n",
    "\n",
    "mean_iou = 0\n",
    "\n",
    "if 'IoU' in overlapDF.columns:\n",
    "    mean_iou = overlapDF.loc[:, \"IoU\"].mean()\n",
    "\n",
    "ground_truth_sum = len(groundTruth)\n",
    "true_positives = len(insert_spots)\n",
    "false_positives = motifs_to_discover - true_positives  # Incorrectly identified motifs\n",
    "false_negatives = ground_truth_sum - true_positives  # Relevant motifs not identified\n",
    "\n",
    "# Precision\n",
    "precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "# Recall\n",
    "recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "# F1-Score\n",
    "f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "print(f\"F1-Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Create a figure with 1 row and 2 columns\u001b[39;00m\n\u001b[0;32m      5\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "# Create a figure with 1 row and 2 columns\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# --- Bar Chart ---\n",
    "metrics = ['F1-Score', 'Recall', 'Precision', 'IoU']\n",
    "values = [f1_score, recall, precision, mean_iou]\n",
    "axes[0].bar(metrics, values, color='skyblue')\n",
    "axes[0].set_ylim(0, 1)\n",
    "axes[0].set_title('Performance Metrics', fontsize=14)\n",
    "axes[0].set_ylabel('Score', fontsize=12)\n",
    "for i, v in enumerate(values):\n",
    "    axes[0].text(i, v + 0.02, f\"{v:.2f}\", ha='center', fontsize=10)\n",
    "axes[0].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# --- Violin Plot with Points for IoU ---\n",
    "sns.violinplot(y=overlapDF[\"IoU\"], ax=axes[1], inner=None, color='lightblue')\n",
    "sns.stripplot(y=overlapDF[\"IoU\"], ax=axes[1], color='black', size=3, jitter=0.2)\n",
    "axes[1].set_title(\"IoU Distribution (Violin Plot)\", fontsize=14)\n",
    "axes[1].set_ylabel(\"IoU\", fontsize=12)\n",
    "axes[1].grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Automated Experiment for multiple window sizes\n",
    "\n",
    "### Word2Vec Encoding Based\n",
    "\n",
    "Iterates in the range of window size 25 to 66 over the time series encoded by with word2vec.\n",
    "\n",
    "Can consider windowsize/2 or IoU threshold as quality value for measuring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing size: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 25 completed. Results appending. F1-Score: 0.05454545454545455, Precision: 0.3, Recall: 0.03, IuO: 0.9029304029304029.\n",
      "Processing size: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 26 completed. Results appending. F1-Score: 0.07272727272727272, Precision: 0.4, Recall: 0.04, IuO: 0.9125615763546798.\n",
      "Processing size: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 27 completed. Results appending. F1-Score: 0.07272727272727272, Precision: 0.4, Recall: 0.04, IuO: 0.7590909090909091.\n",
      "Processing size: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 28 completed. Results appending. F1-Score: 0.07272727272727272, Precision: 0.4, Recall: 0.04, IuO: 0.7661708361505521.\n",
      "Processing size: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 29 completed. Results appending. F1-Score: 0.05454545454545455, Precision: 0.3, Recall: 0.03, IuO: 0.9125448028673836.\n",
      "Processing size: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 30 completed. Results appending. F1-Score: 0.05454545454545455, Precision: 0.3, Recall: 0.03, IuO: 0.8977272727272728.\n",
      "Processing size: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 31 completed. Results appending. F1-Score: 0.07272727272727272, Precision: 0.4, Recall: 0.04, IuO: 0.868436465495289.\n",
      "Processing size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 32 completed. Results appending. F1-Score: 0.09090909090909091, Precision: 0.5, Recall: 0.05, IuO: 0.8136675020885548.\n",
      "Processing size: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 33 completed. Results appending. F1-Score: 0.05454545454545455, Precision: 0.3, Recall: 0.03, IuO: 0.7396825396825397.\n",
      "Processing size: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 34 completed. Results appending. F1-Score: 0.03636363636363636, Precision: 0.2, Recall: 0.02, IuO: 0.9714285714285714.\n",
      "Processing size: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 35 completed. Results appending. F1-Score: 0.07272727272727272, Precision: 0.4, Recall: 0.04, IuO: 0.6671393458120627.\n",
      "Processing size: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 36 completed. Results appending. F1-Score: 0.07272727272727272, Precision: 0.4, Recall: 0.04, IuO: 0.6858215327688038.\n",
      "Processing size: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 37 completed. Results appending. F1-Score: 0.09090909090909091, Precision: 0.5, Recall: 0.05, IuO: 0.739348508634223.\n",
      "Processing size: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 38 completed. Results appending. F1-Score: 0.05454545454545455, Precision: 0.3, Recall: 0.03, IuO: 0.9658119658119658.\n",
      "Processing size: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 39 completed. Results appending. F1-Score: 0.07272727272727272, Precision: 0.4, Recall: 0.04, IuO: 0.7122484115597458.\n",
      "Processing size: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 40 completed. Results appending. F1-Score: 0.05454545454545455, Precision: 0.3, Recall: 0.03, IuO: 0.5956753118360995.\n",
      "Processing size: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 41 completed. Results appending. F1-Score: 0.01818181818181818, Precision: 0.1, Recall: 0.01, IuO: 0.5769230769230769.\n",
      "Processing size: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 42 completed. Results appending. F1-Score: 0.03636363636363636, Precision: 0.2, Recall: 0.02, IuO: 0.5900000000000001.\n",
      "Processing size: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 43 completed. Results appending. F1-Score: 0.07272727272727272, Precision: 0.4, Recall: 0.04, IuO: 0.7412518037518037.\n",
      "Processing size: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 44 completed. Results appending. F1-Score: 0.03636363636363636, Precision: 0.2, Recall: 0.02, IuO: 0.5576441102756893.\n",
      "Processing size: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 45 completed. Results appending. F1-Score: 0.03636363636363636, Precision: 0.2, Recall: 0.02, IuO: 0.5662832929782082.\n",
      "Processing size: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 46 completed. Results appending. F1-Score: 0.03636363636363636, Precision: 0.2, Recall: 0.02, IuO: 0.6433811802232855.\n",
      "Processing size: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 47 completed. Results appending. F1-Score: 0.07272727272727272, Precision: 0.4, Recall: 0.04, IuO: 0.7482374292729796.\n",
      "Processing size: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 48 completed. Results appending. F1-Score: 0.07272727272727272, Precision: 0.4, Recall: 0.04, IuO: 0.7457431457431457.\n",
      "Processing size: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 49 completed. Results appending. F1-Score: 0.07272727272727272, Precision: 0.4, Recall: 0.04, IuO: 0.7671927914476208.\n",
      "Processing size: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 50 completed. Results appending. F1-Score: 0.07272727272727272, Precision: 0.4, Recall: 0.04, IuO: 0.7655292160021614.\n",
      "Processing size: 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 51 completed. Results appending. F1-Score: 0.09090909090909091, Precision: 0.5, Recall: 0.05, IuO: 0.7197223671850537.\n",
      "Processing size: 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 52 completed. Results appending. F1-Score: 0.07272727272727272, Precision: 0.4, Recall: 0.04, IuO: 0.766010412069306.\n",
      "Processing size: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 53 completed. Results appending. F1-Score: 0.07272727272727272, Precision: 0.4, Recall: 0.04, IuO: 0.7817663817663817.\n",
      "Processing size: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 54 completed. Results appending. F1-Score: 0.07272727272727272, Precision: 0.4, Recall: 0.04, IuO: 0.7707297726070863.\n",
      "Processing size: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 55 completed. Results appending. F1-Score: 0.07272727272727272, Precision: 0.4, Recall: 0.04, IuO: 0.642391526798183.\n",
      "Processing size: 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 56 completed. Results appending. F1-Score: 0.09090909090909091, Precision: 0.5, Recall: 0.05, IuO: 0.739586524997941.\n",
      "Processing size: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 57 completed. Results appending. F1-Score: 0.09090909090909091, Precision: 0.5, Recall: 0.05, IuO: 0.607091046277666.\n",
      "Processing size: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 58 completed. Results appending. F1-Score: 0.09090909090909091, Precision: 0.5, Recall: 0.05, IuO: 0.7467642938968688.\n",
      "Processing size: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 59 completed. Results appending. F1-Score: 0.09090909090909091, Precision: 0.5, Recall: 0.05, IuO: 0.74688422970344.\n",
      "Processing size: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 60 completed. Results appending. F1-Score: 0.09090909090909091, Precision: 0.5, Recall: 0.05, IuO: 0.6522805832664987.\n",
      "Processing size: 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 61 completed. Results appending. F1-Score: 0.09090909090909091, Precision: 0.5, Recall: 0.05, IuO: 0.7614319629803501.\n",
      "Processing size: 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 62 completed. Results appending. F1-Score: 0.09090909090909091, Precision: 0.5, Recall: 0.05, IuO: 0.759993223151118.\n",
      "Processing size: 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 63 completed. Results appending. F1-Score: 0.05454545454545455, Precision: 0.3, Recall: 0.03, IuO: 0.802262443438914.\n",
      "Processing size: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 64 completed. Results appending. F1-Score: 0.05454545454545455, Precision: 0.3, Recall: 0.03, IuO: 0.7011358506069795.\n",
      "Processing size: 65\n",
      "Loop 65 completed. Results appending. F1-Score: 0.05454545454545455, Precision: 0.3, Recall: 0.03, IuO: 0.7277160982727136.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomho\\OneDrive\\Documents\\VSCode\\TimeSeriesInRPM\\util\\util.py:854: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  set_matches = set_matches._append(dict1, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# ---- Inputs ----\n",
    "log_to_discover = srrt_plus_log\n",
    "log_to_discover_name = \"SRRT_Plus\"\n",
    "# OR\n",
    "log_to_discover = srrt_parallel_log\n",
    "log_to_discover_name = \"SRRT_Parallel\"\n",
    "\n",
    "ContextColumns = [\"targetApp\",\"eventType\",\"url\",\"target.workbookName\",\"target.sheetName\",\"target.id\",\"target.class\",\"target.tagName\",\"target.type\",\"target.name\",\"target.innerText\",\"target.checked\",\"target.href\",\"target.option\",\"target.title\",\"target.innerHTML\"]\n",
    "ContextColumns = ['eventType', 'targetApp', 'target.tagName', 'target.name']\n",
    "\n",
    "NumberOfMotifsToDiscover = 10\n",
    "\n",
    "# ---- Clean log ----\n",
    "if \"tuple:id\" in log_to_discover.columns:\n",
    "    log_to_discover = log_to_discover.drop(columns=[\"tuple:id\"])\n",
    "\n",
    "ui_log_encoded_w2v = util.util.encode_word2vec(srrt_plus_log, orderedColumnsList=ContextColumns)\n",
    "\n",
    "groundTruth = util.uitl.generate_caseid_list(log_to_discover)\n",
    "groundTruth_set = set(groundTruth)\n",
    "ground_truth_sum = len(groundTruth)\n",
    "\n",
    "# ---- Results container ----\n",
    "results = []\n",
    "\n",
    "# ---- Main loop ----\n",
    "size = 25\n",
    "discovery_repeat = False\n",
    "while size <= 65:\n",
    "    print(f\"Processing size: {size}\")\n",
    "    motif_distances, motif_indices, motif_subspaces, motif_mdls = util.util.mine_w2v(ui_log_encoded_w2v,size,NumberOfMotifsToDiscover)\n",
    "\n",
    "    discovered_set = set(motif_indices[0])\n",
    "    if discovered_set or discovery_repeat:\n",
    "\n",
    "        # insert_spots, motif_spots, overlapDF = util.util.compare_sets(groundTruth_set, discovered_set, (size/2))\n",
    "        insert_spots, motif_spots, overlapDF = util.util.compare_sets_IoU(groundTruth_set, discovered_set, window_size=size, iou_threshold=0.5)\n",
    "\n",
    "        if 'IoU' in overlapDF.columns:\n",
    "            mean_iou = overlapDF.loc[:, \"IoU\"].mean()\n",
    "        else:\n",
    "            mean_iou = 0\n",
    "\n",
    "        true_positives = len(insert_spots)\n",
    "        false_positives = NumberOfMotifsToDiscover - true_positives\n",
    "        false_negatives = ground_truth_sum - true_positives\n",
    "        \n",
    "        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "        \n",
    "        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "        f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "\n",
    "        # print(f\"Loop {size} completed. Results appending. F1-Score: {f1_score}, Precision: {precision}, Recall: {recall}, IuO: {mean_iou}.\")\n",
    "        results.append({\n",
    "            'window_size': size,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1_score,\n",
    "            'mean_iou': mean_iou,\n",
    "            'discovered_indexes': motif_indices\n",
    "        })\n",
    "        size += 1\n",
    "        discovery_repeat = False\n",
    "    else:\n",
    "        discovery_repeat = True\n",
    "\n",
    "\n",
    "# ---- Save the results ----\n",
    "results_df = pd.DataFrame(results)\n",
    "timestamp = datetime.now().strftime(\"%y%m%d_%H%M\")\n",
    "results_df.to_csv(f'ExperimentResult/{timestamp}_w2v_iuo_{log_to_discover_name}.csv', index=False)\n",
    "# print(results_df)\n",
    "\n",
    "# ---- Plot F1-Score vs Window Size ----\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(results_df['window_size'], results_df['f1_score'], marker='o', linewidth=2, label='F1-Score')\n",
    "plt.plot(results_df['window_size'], results_df['recall'], marker='x', linewidth=2, label='Recall')\n",
    "plt.plot(results_df['window_size'], results_df['precision'], marker='+', linewidth=2, label='Precision')\n",
    "plt.plot(results_df['window_size'], results_df['mean_iou'], marker='s', linewidth=2, label='Mean IoU')\n",
    "\n",
    "plt.title('Effect of Window Size on F1-Score', fontsize=16)\n",
    "plt.xlabel('Window Size', fontsize=14)\n",
    "plt.ylabel('F1-Score', fontsize=14)\n",
    "plt.xticks(results_df['window_size'], rotation=45)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.legend(fontsize=12)\n",
    "# ---- Save to file ----\n",
    "plt.savefig(f\"ExperimentResult/{timestamp}_plot_{log_to_discover_name}.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Archive\n",
    "\n",
    "Old encoding method. Improved after reviewer feedback and experiment results in the notebook above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Hot Encoding Method(s)\n",
    "\n",
    "Based on the context columns the discovery will be executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_series shape: (9594,)\n",
      "tm_matrix shape: (9570, 4)\n",
      "tm_matrix[:,0] shape: (9570,)\n",
      "Discovered: [   6   32  110  136  189  215  270  296  351  377  432  458  511  537\n",
      "  593  673  699  754  780  835  861  914  940  995 1021]\n"
     ]
    }
   ],
   "source": [
    "log_to_discover = srrt_plus_log\n",
    "#log_to_discover = srrt_parallel_log\n",
    "\n",
    "# ContextColumns = [\"targetApp\",\"eventType\",\"url\",\"target.workbookName\",\"target.sheetName\",\"target.id\"] # Leno Attributes\n",
    "ContextColumns = [\"targetApp\",\"eventType\",\"url\",\"target.workbookName\",\"target.sheetName\",\"target.id\",\"target.class\",\"target.tagName\",\"target.type\",\"target.name\",\"target.innerText\",\"target.checked\",\"target.href\",\"target.option\",\"target.title\",\"target.innerHTML\"]\n",
    "\n",
    "size = 25\n",
    "NumberOfMotifsToDiscover = 25\n",
    "\n",
    "# ---- Generating Ground Truth ----\n",
    "groundTruth = util.util.generate_caseid_list(log_to_discover)\n",
    "\n",
    "# ---- Reading the File ----\n",
    "if \"tuple:id\" in log_to_discover.columns:\n",
    "    log_to_discover = log_to_discover.drop(columns=[\"tuple:id\"])\n",
    "uiLog_Encoding_method = 3 # 1=Hierarchy Encoding, 2=Co-Occurrance Encoding, 3=Hot Encoding\n",
    "\n",
    "uiLog = util.util.encoding_UiLog(log_to_discover,orderedColumnsList=ContextColumns,encoding=uiLog_Encoding_method)\n",
    "\n",
    "# ---- Time Series Mining ----\n",
    "tm_matrix, event_series = util.util.discover_motifs(uiLog, window_size=size, normalize=True)\n",
    "\n",
    "print(f\"event_series shape: {event_series.shape}\")\n",
    "print(f\"tm_matrix shape: {tm_matrix.shape}\")\n",
    "print(f\"tm_matrix[:,0] shape: {tm_matrix[:,0].shape}\")\n",
    "\n",
    "# The motifs have to be exclusive, thus, no one activity must be part of a routine already discovered\n",
    "config.STUMPY_EXCL_ZONE_DENOM = 1  # The exclusion zone is i ± m\n",
    "top_motifs = stumpy.motifs(T=event_series, P=tm_matrix[:,0], min_neighbors=1, max_matches=NumberOfMotifsToDiscover, cutoff=5)\n",
    "# Identify the outlier\n",
    "discord_idx = np.argsort(tm_matrix[:, 0])[-1]\n",
    "print(f\"Discovered: {np.sort(top_motifs[1][0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Quality Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Ground Truth:{np.sort(groundTruth)}\")\n",
    "\n",
    "# For 1-dim time series\n",
    "insert_spots, motif_spots, overlapDF = util.util.compare_sets(set(groundTruth), set(top_motifs[1][0]), (size/2))\n",
    "\n",
    "ground_truth_sum = len(groundTruth)\n",
    "true_positives = len(insert_spots)\n",
    "false_positives = NumberOfMotifsToDiscover - true_positives  # Incorrectly identified motifs\n",
    "false_negatives = ground_truth_sum - true_positives  # Relevant motifs not identified\n",
    "\n",
    "# Precision\n",
    "precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "# Recall\n",
    "recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "# F1-Score\n",
    "f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "print(f\"F1-Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Automated Experiment for multiple window sizes\n",
    "### A. Hot Encoding Based Multi Window Experiment\n",
    "\n",
    "The following code tests multiple window sizes againts the encoding method and number of motifs to be discovered and visualizes the F1-Score trend afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Inputs ----\n",
    "log_to_discover = srrt_plus_log\n",
    "# log_to_discover = srrt_parallel_log\n",
    "\n",
    "ContextColumns = [\"targetApp\",\"eventType\",\"url\",\"target.workbookName\",\"target.sheetName\",\"target.id\",\"target.class\",\"target.tagName\",\"target.type\",\"target.name\",\"target.innerText\",\"target.checked\",\"target.href\",\"target.option\",\"target.title\",\"target.innerHTML\"]\n",
    "ContextColumns = ['eventType', 'targetApp', 'target.tagName', 'target.name']\n",
    "\n",
    "\n",
    "NumberOfMotifsToDiscover = 10\n",
    "uiLog_Encoding_method = 3  # 1=Hierarchy Encoding, 2=Co-Occurrance Encoding, 3=Hot Encoding\n",
    "\n",
    "# ---- Clean log ----\n",
    "if \"tuple:id\" in log_to_discover.columns:\n",
    "    log_to_discover = log_to_discover.drop(columns=[\"tuple:id\"])\n",
    "\n",
    "uiLog = util.util.encoding_UiLog(log_to_discover, orderedColumnsList=ContextColumns, encoding=uiLog_Encoding_method)\n",
    "\n",
    "\n",
    "groundTruth = util.util.generate_caseid_list(log_to_discover)\n",
    "groundTruth_set = set(groundTruth)\n",
    "ground_truth_sum = len(groundTruth)\n",
    "\n",
    "# ---- Results container ----\n",
    "results = []\n",
    "\n",
    "# ---- Main loop ----\n",
    "for size in range(25, 66):\n",
    "    uiLog = util.util.encoding_UiLog(log_to_discover, orderedColumnsList=ContextColumns, encoding=uiLog_Encoding_method)\n",
    "    tm_matrix, event_series = util.util.discover_motifs(uiLog, window_size=size, normalize=True)\n",
    "    \n",
    "    config.STUMPY_EXCL_ZONE_DENOM = 1\n",
    "    top_motifs = stumpy.motifs(T=event_series, P=tm_matrix[:, 0], min_neighbors=1, max_matches=NumberOfMotifsToDiscover, cutoff=5)\n",
    "    \n",
    "    discovered_set = set(top_motifs[1][0])\n",
    "    insert_spots, motif_spots, overlapDF = util.util.compare_sets(groundTruth_set, discovered_set, (size/2))\n",
    "    # insert_spots, motif_spots, overlapDF = util.util.compare_sets_IoU(groundTruth_set, discovered_set, window_size=size, iou_threshold=0.5)\n",
    "\n",
    "    true_positives = len(insert_spots)\n",
    "    false_positives = NumberOfMotifsToDiscover - true_positives\n",
    "    false_negatives = ground_truth_sum - true_positives\n",
    "    \n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    \n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    results.append({\n",
    "        'window_size': size,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score\n",
    "    })\n",
    "\n",
    "    # print(\"Execution completed for window size:\" + str(size))\n",
    "\n",
    "# ---- Save the results ----\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('motif_discovery_window_size_experiment.csv', index=False)\n",
    "# print(results_df)\n",
    "\n",
    "# ---- Plot F1-Score vs Window Size ----\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(results_df['window_size'], results_df['f1_score'], marker='o', linewidth=2)\n",
    "\n",
    "plt.title('Effect of Window Size on F1-Score', fontsize=16)\n",
    "plt.xlabel('Window Size', fontsize=14)\n",
    "plt.ylabel('F1-Score', fontsize=14)\n",
    "plt.xticks(results_df['window_size'], rotation=45)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualisation\n",
    "\n",
    "Not Maintained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- DFG Mining ----\n",
    "caseuiLog = util.util.reduceLogToDiscovered(uiLog,top_motifs[1][0],size)\n",
    "end_time = time.time()\n",
    "\n",
    "cols = [\"targetApp\",\"eventType\"]\n",
    "caseuiLog[\"concept:name\"] = caseuiLog[cols].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
    "caseuiLog[\"time:timestamp\"] = caseuiLog[\"timeStamp\"]\n",
    "caseuiLog['case:concept:name'] = caseuiLog['case:concept:name'].astype('int64')\n",
    "pm4pyDf = pm4py.format_dataframe(caseuiLog)\n",
    "uiLogDFG, start_activities, end_activities = pm4py.discover_dfg(pm4pyDf)\n",
    "pm4py.view_dfg(uiLogDFG, start_activities, end_activities)\n",
    "\n",
    "# ---- Motif Visualisation ----\n",
    "starting_row = 0\n",
    "ending_row = len(uiLog)-1\n",
    "ids = uiLog.loc[starting_row:ending_row,'tuple:id'].tolist()\n",
    "rows = [i for i in range(len(uiLog.loc[starting_row:ending_row,'tuple:id']))]\n",
    "\n",
    "#Plot Event data\n",
    "fig2, axs2 = plt.subplots(3, sharex=True, gridspec_kw={'hspace': 0})\n",
    "plt.suptitle('Motif (Routine) Discovery', fontsize='10')\n",
    "\n",
    "axs2[0].scatter(rows, ids, alpha=0.8)\n",
    "axs2[0].set_ylabel('Events', fontsize='10')\n",
    "# Plot Timeseries data\n",
    "axs2[1].plot(event_series)\n",
    "axs2[1].set_ylabel('Timeseries', fontsize='10')\n",
    "# Plot Matrix profiles\n",
    "axs2[2].set_xlabel('Activity', fontsize ='10')\n",
    "axs2[2].set_ylabel('Matrix Profile', fontsize='10')\n",
    "axs2[2].set_ylim(top=tm_matrix[:, 0].max()*1.1) #displaying the max value with some uplift for space in Graph\n",
    "axs2[2].plot(tm_matrix[:, 0])\n",
    "# Adding Dashed lines\n",
    "for discovered in top_motifs[1][0]:\n",
    "    axs2[0].axvline(x=discovered, linestyle=\"dashed\",color='C1')\n",
    "    #axs2[1].axvline(x=discovered, linestyle=\"dashed\",color='C1')\n",
    "    axs2[2].axvline(x=discovered, linestyle=\"dashed\",color='C1')\n",
    "\n",
    "# Display Pattern overlay\n",
    "fig, ax = plt.subplots(figsize=(6.5, 2))\n",
    "plt.title('Motif Overlay', fontsize='10')\n",
    "ax.set_xlabel(\"Events\", fontsize='10')\n",
    "ax.set_ylabel(\"Timeseries\", fontsize='10')\n",
    "# Plot motif and nearest neighbor window\n",
    "for i, val in enumerate(top_motifs[1][0]):\n",
    "    colorPlot = 'C' + str(i)\n",
    "    ax.plot(event_series[val:val+size], color=colorPlot, label=f\"Motif {i}\")\n",
    "    \n",
    "plt.legend(loc=\"best\",fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeSeriesData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
