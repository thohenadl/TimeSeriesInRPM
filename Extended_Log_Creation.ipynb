{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b814bb64",
   "metadata": {},
   "source": [
    "# Notebook to generate an extended UI Log\n",
    "\n",
    "Based on the Student Record (SR) and Reimbursement (RT) logs from Leno et al., this notebook generates an extended version of the log.\n",
    "\n",
    "The logs are in the folder called \"Leno\".\n",
    "\n",
    "Properties of the original logs:\n",
    "1. SR_RT_joint: Containing all Student Record traces and afterwards all Reimbursement traces.\n",
    "2. ST_RT_paarallel: Contains all Student Records traces alternating with all Reimbursement traces.\n",
    "\n",
    "Gathering of the original Leno data from https://figshare.com/articles/dataset/UI_logs/12543587\n",
    "\n",
    "Properties of the Extended Logs:\n",
    "1. Extended_SR_RT_joint: Between all traces there are X randomly generated events. X can be set in this notebook.\n",
    "2. Extended_ST_RT_parallel: Same as for Extended_SR_RT_joint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8a8ff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = 'Leno/'\n",
    "srrt_plus_filename = \"SR_RT_joint.csv\"\n",
    "srrt_parallel_filename = \"SR_RT_parallel.csv\"\n",
    "\n",
    "text_encoding_method = \"utf-8\"\n",
    "seperator = \";\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc5bd88",
   "metadata": {},
   "source": [
    "#### Execution of Log Generation for Discovery\n",
    "\n",
    "Generating two extended logs\n",
    "1. Adding a case id for all existing cases\n",
    "2. Adding 50 random actions between all cases to simulate long time recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6663b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of SRRT+ Log:  4644\n",
      "Length of SRRT|| Log:  4644\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 174\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of SRRT|| Log: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(srrt_parallel_log))\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# Add Caseids for discovery and random noise\u001b[39;00m\n\u001b[1;32m--> 174\u001b[0m srrt_plus_log \u001b[38;5;241m=\u001b[39m \u001b[43madd_caseid_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrrt_plus_log\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrandom_insert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mnum_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m srrt_parallel_log \u001b[38;5;241m=\u001b[39m add_caseid_column(srrt_parallel_log,random_insert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,num_rows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;66;03m#print(srrt_plus_log)\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# Storing Files\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 21\u001b[0m, in \u001b[0;36madd_caseid_column\u001b[1;34m(df, random_insert, num_rows)\u001b[0m\n\u001b[0;32m     18\u001b[0m df\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcaseid\u001b[39m\u001b[38;5;124m\"\u001b[39m, caseid_list)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m random_insert:\n\u001b[1;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minsert_random_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_rows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "Cell \u001b[1;32mIn[4], line 34\u001b[0m, in \u001b[0;36minsert_random_rows\u001b[1;34m(df, num_rows)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df)):\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m df\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcaseid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m prev_caseid:\n\u001b[1;32m---> 34\u001b[0m         new_df_parts\u001b[38;5;241m.\u001b[39mextend(\u001b[43mgenerate_random_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_rows\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     35\u001b[0m     new_df_parts\u001b[38;5;241m.\u001b[39mappend(pd\u001b[38;5;241m.\u001b[39mDataFrame([df\u001b[38;5;241m.\u001b[39miloc[i]]))\n\u001b[0;32m     36\u001b[0m     prev_caseid \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcaseid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[1;32mIn[4], line 157\u001b[0m, in \u001b[0;36mgenerate_random_rows\u001b[1;34m(df, num_rows, frac_synthetic)\u001b[0m\n\u001b[0;32m    154\u001b[0m             row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.type\u001b[39m\u001b[38;5;124m\"\u001b[39m]         \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    155\u001b[0m             row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.href\u001b[39m\u001b[38;5;124m\"\u001b[39m]         \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 157\u001b[0m     new_rows\u001b[38;5;241m.\u001b[39mappend(\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_rows\u001b[38;5;241m.\u001b[39msample(frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\tomho\\anaconda3\\envs\\timeSeriesData\\lib\\site-packages\\pandas\\core\\frame.py:733\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    727\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    728\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    729\u001b[0m     )\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\tomho\\anaconda3\\envs\\timeSeriesData\\lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tomho\\anaconda3\\envs\\timeSeriesData\\lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\tomho\\anaconda3\\envs\\timeSeriesData\\lib\\site-packages\\pandas\\core\\internals\\construction.py:667\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    664\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[1;32m--> 667\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_series:\n\u001b[0;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m union_indexes(indexes)\n",
      "\u001b[1;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "def generate_random_rows(df: pd.DataFrame, num_rows: int) -> list[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Generates a list of random rows from existing DataFrame values, and adds random data for URL,\n",
    "    content, and target.workbookName columns.\n",
    "    \"\"\"\n",
    "    shuffled_rows: list[pd.DataFrame] = []\n",
    "    columns_to_shuffle = [col for col in df.columns if col != \"caseid\"]\n",
    "    \n",
    "    # Predefined lists for random data\n",
    "    random_actions = [\n",
    "        \"copyCell\", \"paste\", \"editField\", \"clickButton\", \"clickLink\", \"selectWorksheet\",\n",
    "        \"copyRange\", \"form_submit\", \"createNewTab\"\n",
    "    ]\n",
    "\n",
    "    random_urls = [\n",
    "        \"https://example.com\", \"https://example.org\", \"https://example.net\", \"\", \" \", \n",
    "        \"https://randomsite.com\", \"https://testsite.com\", \"https://anotherurl.com\", \n",
    "        \"https://sap.example.com\", \"https://service-now.example.com\", \"https://salesforce.example.com\", \n",
    "        \"https://jira.example.com\", \"https://confluence.example.com\", \"https://microsoft.com\", \n",
    "        \"https://office365.example.com\", \"https://slack.com\", \"https://zoom.us\", \n",
    "        \"https://google.com\", \"https://github.com\", \"https://linkedin.com\", \n",
    "        \"https://workday.example.com\", \"https://oracle.com\", \"https://adobe.com\"\n",
    "    ]\n",
    "    random_content = [\n",
    "        \"Lorem ipsum dolor sit amet.\", \"This is a random content example.\", \n",
    "        \"Random text for data generation.\", \"\", \" \", \"Sample content for testing.\", \n",
    "        \"Another random string.\", \"Test content for the application.\", \n",
    "        \"Placeholder text for demonstration.\", \"Randomly generated content.\"\n",
    "    ]\n",
    "    random_file_names = [\n",
    "        \"report_final.xlsx\", \"data_analysis.csv\", \"project_notes.pdf\", \"budget_2023.xlsx\",\n",
    "        \"presentation.csv\", \"meeting_minutes.xlsx\", \"research_paper.xml\"\n",
    "    ]\n",
    "    random_cell_names = [\n",
    "        \"A1\", \"B2\", \"C3\", \"D4\", \"E5\", \"F6\", \"G7\", \"H8\", \"I9\", \"J10\", \"K11\", \"L12\",\n",
    "        \"M13\", \"N14\", \"O15\", \"P16\", \"Q17\", \"R18\", \"S19\", \"T20\", \"U21\", \"V22\", \"W23\",\n",
    "        \"X24\", \"Y25\", \"Z26\", \"AA27\", \"AB28\", \"AC29\", \"AD30\", \"AE31\", \"AF32\", \"AG33\",\n",
    "    ]\n",
    "    random_html_tags = [\n",
    "        \"div\", \"span\", \"p\", \"a\", \"img\", \"h5\", \"h6\", \"ul\", \"ol\", \"li\",\n",
    "        \"table\", \"form\", \"input\", \"button\", \"select\", \"option\", \"textarea\", \"label\"\n",
    "    ]\n",
    "    random_sheet_names = [\n",
    "        \"Sheet1\", \"Sheet2\", \"Sheet3\", \"Sheet4\", \"Sheet5\", \"Sheet6\", \"Sheet7\"\n",
    "    ]\n",
    "    \n",
    "    for _ in range(num_rows):\n",
    "        # Shuffle other columns' values\n",
    "        random_row: dict = {col: random.choice(df[col].tolist()) for col in columns_to_shuffle}\n",
    "        \n",
    "        # Add random values for specific columns\n",
    "        random_row[\"eventType\"] = random.choice(random_actions)  # Random URL\n",
    "        random_row[\"content\"] = random.choice(random_content)  # Random personal content\n",
    "        \n",
    "        if random_row[\"targetApp\"] == \"Chrome\":\n",
    "            random_row[\"target.sheetName\"] = \"\"  # Empty for non-Excel apps\n",
    "            random_row[\"target.workbookName\"] = \"\"  # Empty for non-Excel apps\n",
    "            random_row[\"url\"] = random.choice(random_urls)  # Random URL\n",
    "            random_row[\"target.id\"] = random.choice(random_html_tags)  # Random HTML tag\n",
    "        if random_row[\"targetApp\"] == \"Excel\":\n",
    "            random_row[\"target.id\"] = random.choice(random_cell_names)  # Random cell name\n",
    "            random_row[\"target.workbookName\"] = random.choice(random_file_names)  # Random file name\n",
    "            random_row[\"target.sheetName\"] = random.choice(random_sheet_names)  # Random sheet name\n",
    "            random_row[\"target.tagName\"] = \"\" # Empty for Excel\n",
    "            random_row[\"url\"] = \"\" # Empty for Excel\n",
    "            random_row[\"target.type\"] = \"\" # Empty for Excel\n",
    "            random_row[\"target.href\"] = \"\"\n",
    "        \n",
    "        shuffled_rows.append(pd.DataFrame([random_row])) \n",
    "                                            \n",
    "    return shuffled_rows\n",
    "                                            \n",
    "\n",
    "# Ensure the DataFrames are empty before adding data\n",
    "srrt_plus_log = pd.DataFrame()  \n",
    "# srrt_parallel_log = pd.DataFrame()\n",
    "\n",
    "# Read the original CSV Logs from Leno et al\n",
    "srrt_plus_log = pd.read_csv(file_path + srrt_plus_filename, encoding=text_encoding_method, sep=seperator)\n",
    "print(\"Lenght of SRRT+ Log: \", len(srrt_plus_log))\n",
    "srrt_parallel_log = pd.read_csv(file_path + srrt_parallel_filename, encoding=text_encoding_method, sep=seperator)\n",
    "print(\"Length of SRRT|| Log: \", len(srrt_parallel_log))\n",
    "\n",
    "# Add Caseids for discovery and random noise\n",
    "srrt_plus_log = add_caseid_column(srrt_plus_log,random_insert=True,num_rows=25)\n",
    "srrt_parallel_log = add_caseid_column(srrt_parallel_log,random_insert=True,num_rows=25)\n",
    "#print(srrt_plus_log)\n",
    "\n",
    "# Storing Files\n",
    "timestamp = datetime.now().strftime(\"%y%m%d_%H%M\")\n",
    "full_path_srrt_plus = file_path + f\"{timestamp}_extended_\" + srrt_plus_filename\n",
    "full_path_srrt_parallel = file_path + f\"{timestamp}_extended_\" + srrt_parallel_filename\n",
    "srrt_plus_log.to_csv(full_path_srrt_plus, index=False, sep=seperator) \n",
    "srrt_parallel_log.to_csv(full_path_srrt_parallel, index=False, sep=seperator)\n",
    "\n",
    "print(\"Lenght of SRRT+ Log: \", len(srrt_plus_log))\n",
    "print(\"Length of SRRT|| Log: \", len(srrt_parallel_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498970a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeSeriesData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
