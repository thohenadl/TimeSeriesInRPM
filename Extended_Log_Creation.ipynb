{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b814bb64",
   "metadata": {},
   "source": [
    "# Notebook to generate an extended UI Log\n",
    "\n",
    "Based on the Student Record (SR) and Reimbursement (RT) logs from Leno et al., this notebook generates an extended version of the log.\n",
    "\n",
    "The logs are in the folder called \"Leno\".\n",
    "\n",
    "Properties of the original logs:\n",
    "1. SR_RT_joint: Containing all Student Record traces and afterwards all Reimbursement traces.\n",
    "2. ST_RT_paarallel: Contains all Student Records traces alternating with all Reimbursement traces.\n",
    "\n",
    "Gathering of the original Leno data from https://figshare.com/articles/dataset/UI_logs/12543587\n",
    "\n",
    "Properties of the Extended Logs:\n",
    "1. Extended_SR_RT_joint: Between all traces there are X randomly generated events. X can be set in this notebook.\n",
    "2. Extended_ST_RT_parallel: Same as for Extended_SR_RT_joint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8a8ff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = 'Leno/'\n",
    "srrt_plus_filename = \"SR_RT_joint.csv\"\n",
    "srrt_parallel_filename = \"SR_RT_parallel.csv\"\n",
    "\n",
    "text_encoding_method = \"utf-8\"\n",
    "seperator = \";\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc5bd88",
   "metadata": {},
   "source": [
    "#### Execution of Log Generation for Discovery\n",
    "\n",
    "Generating two extended logs\n",
    "1. Adding a case id for all existing cases\n",
    "2. Adding 50 random actions between all cases to simulate long time recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc6663b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_caseid_column(df: pd.DataFrame, random_insert: bool = True, num_rows: int = 50) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds a 'caseid' column to the DataFrame, incrementing the case ID after every `num_rows` rows or at random points if `random_insert` is True.\n",
    "    \"\"\"\n",
    "    target_url: str = \"https://forms.zoho.com/universityofmelbourne/form/NewRecord/thankyou\"\n",
    "    target_event: str = \"createNewTab\"\n",
    "    caseid: int = 1\n",
    "    caseid_list: list[int] = []\n",
    "    \n",
    "    if \"caseid\" in df.columns:\n",
    "        df = df.drop(columns=[\"caseid\"])\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        caseid_list.append(caseid)\n",
    "        if row[\"url\"] == target_url or (\"eventType\" in df.columns and row[\"eventType\"] == target_event):\n",
    "            caseid += 1\n",
    "    \n",
    "    df.insert(0, \"caseid\", caseid_list)\n",
    "    \n",
    "    if random_insert:\n",
    "        return insert_random_rows(df, num_rows=num_rows)\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "def insert_random_rows(df: pd.DataFrame, num_rows: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Inserts \"num_rows\" random rows at each caseid transition point.\n",
    "    \"\"\"\n",
    "    new_df_parts: list[pd.DataFrame] = []\n",
    "    prev_caseid = df.iloc[0][\"caseid\"]\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        if i > 0 and df.iloc[i][\"caseid\"] != prev_caseid:\n",
    "            new_df_parts.extend(generate_random_rows(df, num_rows))\n",
    "        new_df_parts.append(pd.DataFrame([df.iloc[i]]))\n",
    "        prev_caseid = df.iloc[i][\"caseid\"]\n",
    "    \n",
    "    return pd.concat(new_df_parts, ignore_index=True)\n",
    "\n",
    "def generate_random_rows(df: pd.DataFrame, num_rows: int) -> list[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Generates a list of random rows from existing DataFrame values, and adds random data for URL,\n",
    "    content, and target.workbookName columns.\n",
    "    \"\"\"\n",
    "    shuffled_rows: list[pd.DataFrame] = []\n",
    "    columns_to_shuffle = [col for col in df.columns if col != \"caseid\"]\n",
    "    \n",
    "    # Predefined lists for random data\n",
    "    random_actions = [\n",
    "    \"doubleClick\", \"drag\", \"closeWindow\", \"scroll\", \"click\", \"hover\", \"resize\", \"select\", \n",
    "    \"submit\", \"download\", \"upload\", \"edit\", \"view\", \"delete\", \"create\", \"open\", \"logIn\", \n",
    "    \"logOut\", \"search\", \"refresh\", \"approve\", \"reject\"\n",
    "    ]\n",
    "\n",
    "    random_urls = [\n",
    "        \"https://example.com\", \"https://example.org\", \"https://example.net\", \"\", \" \", \n",
    "        \"https://randomsite.com\", \"https://testsite.com\", \"https://anotherurl.com\", \n",
    "        \"https://sap.example.com\", \"https://service-now.example.com\", \"https://salesforce.example.com\", \n",
    "        \"https://jira.example.com\", \"https://confluence.example.com\", \"https://microsoft.com\", \n",
    "        \"https://office365.example.com\", \"https://slack.com\", \"https://zoom.us\", \n",
    "        \"https://google.com\", \"https://github.com\", \"https://linkedin.com\", \n",
    "        \"https://workday.example.com\", \"https://oracle.com\", \"https://adobe.com\"\n",
    "    ]\n",
    "    random_content = [\n",
    "        \"Lorem ipsum dolor sit amet.\", \"This is a random content example.\", \n",
    "        \"Random text for data generation.\", \"\", \" \"\n",
    "    ]\n",
    "    random_file_names = [\n",
    "        \"report_final.xlsx\", \"data_analysis.csv\", \"project_notes.pdf\", \"\", \" \"\n",
    "    ]\n",
    "    \n",
    "    for _ in range(num_rows):\n",
    "        # Shuffle other columns' values\n",
    "        random_row: dict = {col: random.choice(df[col].tolist()) for col in columns_to_shuffle}\n",
    "        \n",
    "        # Add random values for specific columns\n",
    "        random_row[\"eventType\"] = random.choice(random_actions)  # Random URL\n",
    "        random_row[\"url\"] = random.choice(random_urls)  # Random URL\n",
    "        random_row[\"content\"] = random.choice(random_content)  # Random personal content\n",
    "        random_row[\"target.workbookName\"] = random.choice(random_file_names)  # Random file name\n",
    "        \n",
    "        shuffled_rows.append(pd.DataFrame([random_row])) \n",
    "                                            \n",
    "    return shuffled_rows\n",
    "\n",
    "\n",
    "# Ensure the DataFrames are empty before adding data\n",
    "srrt_plus_log = pd.DataFrame()  \n",
    "# srrt_parallel_log = pd.DataFrame()\n",
    "\n",
    "# Read the original CSV Logs from Leno et al\n",
    "srrt_plus_log = pd.read_csv(file_path + srrt_plus_filename, encoding=text_encoding_method, sep=seperator)\n",
    "srrt_parallel_log = pd.read_csv(file_path + srrt_parallel_filename, encoding=text_encoding_method, sep=seperator)\n",
    "\n",
    "# Add Caseids for discovery and random noise\n",
    "srrt_plus_log = add_caseid_column(srrt_plus_log,random_insert=True,num_rows=50)\n",
    "srrt_parallel_log = add_caseid_column(srrt_parallel_log,random_insert=True,num_rows=50)\n",
    "#print(srrt_plus_log)\n",
    "\n",
    "# Storing Files\n",
    "timestamp = datetime.now().strftime(\"%y%m%d_%H%M\")\n",
    "full_path_srrt_plus = file_path + f\"{timestamp}_extended_\" + srrt_plus_filename\n",
    "full_path_srrt_parallel = file_path + f\"{timestamp}_extended_\" + srrt_parallel_filename\n",
    "srrt_plus_log.to_csv(full_path_srrt_plus, index=False, sep=seperator) \n",
    "srrt_parallel_log.to_csv(full_path_srrt_parallel, index=False, sep=seperator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeSeriesData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
